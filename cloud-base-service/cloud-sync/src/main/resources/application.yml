server:
  port: 8002
spring:
  application:
    name: cloud-sync
  datasource:
    url: jdbc:mysql://localhost/cloud_sync?characterEncoding=utf8&zeroDateTimeBehavior=convertToNull&useSSL=false&useJDBCCompliantTimezoneShift=true&useLegacyDatetimeCode=false&serverTimezone=GMT%2B8&nullCatalogMeansCurrent=true
    username: root
    password: 123456
    hikari:
      maximumPoolSize: 10
      minimumIdle: 2
      idleTimeout: 600000
      connectionTimeout: 30000
      maxLifetime: 1800000
  kafka:
    #本地虚拟机kafka伪集群
    bootstrap-servers: 127.0.0.1:9092
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      batch-size: 65536
      buffer-memory: 524288
    consumer:
      group-id: default-group   #默认组id  后面会配置多个消费者组
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      auto-offset-reset: latest
      enable-auto-commit: false   #关闭自动提交 改由spring-kafka提交
      auto-commit-interval: 100
      fetch-max-wait: 1000  # poll 一次拉取的阻塞的最大时长，单位：毫秒。这里指的是阻塞拉取需要满足至少 fetch-min-size 大小的消息
      fetch-min-size: 100000   # poll 一次消息拉取的最小数据量，单位：字节
      max-poll-records: 2000      #批量消费 一次接收的最大数量
    listener:
      type: batch # 开启批量监听
      concurrency: 3 # 设置并发数
    topic:
      #自定义的topic .*模糊匹配
      startTopic: debezium_
      debeziumTopic: ${spring.kafka.topic.startTopic}.*
# 指定注册中心的地址
eureka:
  client:
    serviceUrl:
      defaultZone: http://127.0.0.1:8000/eureka/
  instance:
    preferIpAddress: true

logging:
  level:
    learning: error

mybatis-plus:
  configuration:
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl